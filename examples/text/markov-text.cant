;; Markov text generator
;; TODO:
;; - separate a module from the main program

(import (use 'chaos) random-chaos<-)
(import (use 'text-wrap) fill)
(import (use 'parson) like)

(let order 2) ; Length of the context. TODO parameterize at command line
(let start ('("START") .repeat order)) 

(to (main argv)
  (let model (!map<-))
  (for each! ((filename argv.rest))
    (train model (tokenize (with-input-file ~.read-all filename))))
  (unless model.none?
    (let tokens (spew (random-chaos<- system-randomness-source<-) model start))
    (out .display (fill (" " .join tokens) ;TODO fill sort of splits it back -- add a function to text-wrap that wouldn't need to?
                        72))
    out.newline))

;; TODO include non-word tokens, and format them appropriately above (adding spaces only between words):
(to (tokenize text) (scan-words text.lowercase))
(let scan-words (like "({:letter+} | :skip)*"))

;; A model is a map from a context to a bag of possible next tokens.
;; A context is a token-list of length `order`.

(to (train model input)
  (let data (chain start input '("END"))) ;TODO as array?
  (for each! ((datum (k-slices<- data order.+)))
    (let context (datum .slice 0 order))
    ((model .get-set! context bag<-) .add! (datum order))))

(to (k-slices<- xs k)                   ;ugly: better name?
  (for each ((i (0 .thru (- xs.count k))))
    (xs .slice i (+ i k))))

(to (spew chaos model state)
  (begin spewing ((state state))
    (may ((model state) .weighted-sample chaos)
      (be "END"
        '())
      (be choice
        (let next-state `(,@(state .slice 1) ,choice))
        (link choice (spewing next-state))))))
