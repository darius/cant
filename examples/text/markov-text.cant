;; Markov text generator
;; TODO:
;; - separate a module from the main program

(import (use 'chaos) random-chaos<-)
(import (use 'text-wrap) fill)
(import (use 'parson) like)

(let order 2) ; Length of the context. TODO parameterize at command line
(let start ('("START") .repeat order)) 

(to (main argv)
  (let model (!map<-))
  (for each! ((filename argv.rest))
    (train model (tokenize (with-input-file ~.read-all filename))))
  (when model.some?
    (let tokens (spew (random-chaos<- system-randomness-source<-) model start))
    (out .display (fill (" " .join tokens) ;TODO fill sort of splits it back -- add a function to text-wrap that wouldn't need to?
                        72))
    out.newline))

;; TODO include non-word tokens, and format them appropriately above (adding spaces only between words):
(to (tokenize text) (scan-words text.lowercase))
(let scan-words (like "({:letter+} | :skip)*"))

;; A model is a map from a context to a bag of possible next tokens.
;; A context is a token-list of length `order`.

(to (train model input)
  (let data (chain start input '("END"))) ;TODO as array?
  (for each! ((datum (data .k-slices order.+)))
    (let context (datum .from 0 order))
    ((model .get-set! context bag<-) .add! (datum order))))

(to (spew chaos model state)
  (begin spewing (state)
    (may ((model state) .weighted-sample chaos)
      (be "END"
        '())
      (be choice
        (let next-state `(,@(state .from 1) ,choice))
        (link choice (spewing next-state))))))
